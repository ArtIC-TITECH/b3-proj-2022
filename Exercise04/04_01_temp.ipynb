{
 "cells": [
  {
   "source": [
    "This tutorial is based on PyTorch's tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html and contains the code snippets from it:  \n",
    "- device test\n",
    "- transform, trainset, trainloader, testset, testloader, classes\n",
    "- training, evaluating, and visualizing routines\n",
    "\n",
    "The license of the original tutorial is the 3-Clause BSD License.  \n",
    "See LICENSE for detail.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/Colab Notebooks/b3_proj_2022/MyModules')\n",
    "import util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# To monitor the server's GPU installation and usage: log in the server and run `nvidia-smi`.\n",
    "# It shows the list of GPUs online and their utilization.\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "batch_size_train = 128\n",
    "batch_size_test = 128\n",
    "num_shown_images = 8\n",
    "input_size = 32\n",
    "# input_size = 64\n",
    "\n",
    "study_name = \"exercise04_01_st01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    torchvision.transforms.Resize(input_size),\n",
    "    transforms.RandomCrop(input_size, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.424, 0.415, 0.384), (0.283, 0.278, 0.284))\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    torchvision.transforms.Resize(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.424, 0.415, 0.384), (0.283, 0.278, 0.284))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/content/drive/My Drive/Colab Notebooks/b3_proj_2022/data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size_train,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/content/drive/My Drive/Colab Notebooks/b3_proj_2022/data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size_test,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "\n",
    "# A quantization function that emulates int8 (-128..127) in float expression\n",
    "class Int8InFloatFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return torch.clamp(torch.round(input), -128, 127)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        input = ctx.saved_tensors[0]\n",
    "        return \n",
    "        # TRY!\n",
    "        # Hint: To apply a conditional expression element-wise, torch.where() is useful! \n",
    "    \n",
    "int8_in_float = Int8InFloatFunction.apply\n",
    "\n",
    "\n",
    "# Its nn.Module wrapper with fraction part bit width\n",
    "class Int8Float(nn.Module):\n",
    "    pass\n",
    "    # Implement refering to the manual!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "\n",
    "# A quantization/activation function that emulates binary sign (+1/-1) in float expression\n",
    "class BinarySignFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # Try!\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        # Try!\n",
    "    \n",
    "binary_sign = BinarySignFunction.apply\n",
    "\n",
    "\n",
    "# Its nn.Module wrapper\n",
    "class BinarySign(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinarySign, self).__init__()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return binary_sign(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Conv2d subclass with quantizer option\n",
    "class QuantizedConv2d(nn.Conv2d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        quantizer = kwargs.pop(\"quantizer\", None)\n",
    "        super(QuantizedConv2d, self).__init__(*args, **kwargs)\n",
    "        self.quantizer = quantizer\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # From official source https://pytorch.org/docs/stable/_modules/torch/nn/modules/conv.html\n",
    "        if self.quantizer is not None:\n",
    "            return self._conv_forward(input, self.quantizer(self.weight), self.bias)\n",
    "        return self._conv_forward(input, self.weight, self.bias)\n",
    "\n",
    "# Conv2d subclass with quantizer option\n",
    "class QuantizedLinear(nn.Linear):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Try!\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # From official source https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html\n",
    "        # Try!\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "\n",
    "# Conv層定義用ユーティリティ関数\n",
    "def conv_block(ich, och, ksize, num_layers, *, bn=True, pool=False, act=None, quant=None, **kwargs):\n",
    "    assert num_layers >= 1\n",
    "    r = OrderedDict()\n",
    "    i = 1\n",
    "    for _ in range(num_layers):\n",
    "        r[\"%02d-conv\" % i] = QuantizedConv2d(ich, och, ksize, quantizer=copy.deepcopy(quant), **kwargs)\n",
    "        if bn:\n",
    "            r[\"%02d-conv-bn\" % i] = nn.BatchNorm2d(och)\n",
    "        ich = och  # set #input_channels to current #output_channels for next loop\n",
    "        i += 1\n",
    "    if pool:\n",
    "        r[\"%02d-pool\" % i] = nn.MaxPool2d(2, 2)\n",
    "        i += 1\n",
    "    if act is not None:\n",
    "        r[\"%02d-act\" % i] = copy.deepcopy(act)\n",
    "    return r\n",
    "\n",
    "\n",
    "# FC層定義用ユーティリティ関数\n",
    "def fc_block(ich, och, *, bn=True, pool=False, act=None, quant=None, **kwargs):\n",
    "    r = OrderedDict()\n",
    "    r[\"01-fc\"] = QuantizedLinear(ich, och, quantizer=copy.deepcopy(quant), **kwargs)\n",
    "    if bn:\n",
    "        r[\"01-fc-bn\"] = nn.BatchNorm1d(och)\n",
    "    if act is not None:\n",
    "        r[\"02-act\"] = copy.deepcopy(act)\n",
    "    return r\n",
    "\n",
    "# ネット定義\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        num_conv_blocks = 4\n",
    "        num_conv_layers_per_block = 2\n",
    "        num_fc_layers = 2\n",
    "\n",
    "        if num_fc_layers > 1:\n",
    "            fc_hidden_size = 1024  \n",
    "\n",
    "        act = BinarySign()\n",
    "        # act = nn.ReLU()\n",
    "        \n",
    "        quant = Int8Float(5)\n",
    "        # quant = None\n",
    "        \n",
    "        # Conv層を実体化\n",
    "        conv_blocks = []\n",
    "        conv_blocks.extend(\n",
    "            [(\"conv1/%s\" % k, v) for k, v in conv_block(3, 64, 3, 1, bn=True, pool=False, act=act, padding=1, quant=quant, bias=False).items()]\n",
    "        )\n",
    "        conv_blocks.extend(\n",
    "            [(\"conv2/%s\" % k, v) for k, v in conv_block(64, 128, 3, 1, bn=True, pool=True, act=act, padding=1, quant=quant, bias=False).items()]\n",
    "        )\n",
    "        \n",
    "        # Conv層の実体化 … 上でもらったパラメータを使う\n",
    "        ich = 128\n",
    "        och_max = 512\n",
    "        for i in range(3, num_conv_blocks + 1):\n",
    "            och = min(ich * 2, och_max)\n",
    "            conv_blocks.extend(\n",
    "                [(\"conv%d/%s\" % (i, k), v) for k, v in conv_block(ich, och, 3, num_conv_layers_per_block, bn=True, pool=True, act=act, padding=1, quant=quant, bias=False).items()]\n",
    "            )\n",
    "            ich = och\n",
    "        \n",
    "        # FC層の実体化\n",
    "        fc_blocks = []\n",
    "        ich = och * (input_size >> (num_conv_blocks - 1)) ** 2  # och is still in the scope after the previous FOR statement! 気持ち悪い!\n",
    "        self.fc_input_size = ich\n",
    "        i = 1\n",
    "        for _ in range(1, num_fc_layers):\n",
    "            fc_blocks.extend(\n",
    "                [(\"fc%d/%s\" % (i, k), v) for k, v in fc_block(ich, fc_hidden_size, bn=True, act=act, quant=quant, bias=False).items()]\n",
    "            )\n",
    "            i += 1\n",
    "            ich = fc_hidden_size\n",
    "        fc_blocks.extend(\n",
    "            [(\"fc%d/%s\" % (i, k), v) for k, v in fc_block(ich, num_classes, bn=False, act=None, quant=quant, bias=False).items()]  # 最終層だけactとochの扱いが違う\n",
    "        )\n",
    "        \n",
    "        # モデル定義 … Sequentialの利用\n",
    "        self.conv_blocks = nn.Sequential(OrderedDict(conv_blocks))\n",
    "        self.fc_blocks = nn.Sequential(OrderedDict(fc_blocks))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)\n",
    "        x = x.view(-1, self.fc_input_size)\n",
    "        x = self.fc_blocks(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "\n",
    "# 学習ルーチン\n",
    "def train(net):\n",
    "    date_str = datetime.datetime.now().strftime(\"%y%m%d-%H%M%S\")\n",
    "    basename = \"%s-%s\" % (study_name, date_str)\n",
    "    \n",
    "    print(\"Starting training for '%s'\" % basename)\n",
    "      \n",
    "    lr = 0.000136789\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, 5, gamma=0.1)\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, _ = dataiter.next()\n",
    "    writer = SummaryWriter(\"/content/drive/My Drive/Colab Notebooks/b3_proj_2022/runs/%s\" % basename)\n",
    "    writer.add_graph(net, images.to(device))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Save initial state\n",
    "    util.add_param(writer, net, 0)\n",
    "\n",
    "    try:\n",
    "        for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "            running_loss = 0.0\n",
    "            net.train()\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    train_acc = util.accuracy_batch(outputs, labels)\n",
    "                    print('[%d, %5d] loss: %.3f, train batch acc: %2d %%' %\n",
    "                          (epoch + 1, i + 1, running_loss, train_acc))\n",
    "\n",
    "                    gstep = epoch * len(trainloader) + i\n",
    "                    writer.add_scalar('Training/Loss', running_loss, gstep)\n",
    "                    writer.add_scalar('Training/Accuracy', train_acc, gstep)\n",
    "\n",
    "                    running_loss = 0.0\n",
    "\n",
    "            # Evaluate intermediate result\n",
    "            gstep = epoch * len(trainloader) + i\n",
    "            net.eval()\n",
    "            with util.IntermediateOutputWriter(writer, net, gstep):\n",
    "                test_acc = util.accuracy(testloader, net, device=device)\n",
    "                print('[%d,      ] test acc: %2d %%' %\n",
    "                      (epoch + 1, test_acc))\n",
    "            writer.add_scalar('Test/Accuracy', test_acc, gstep)\n",
    "            util.add_param(writer, net, gstep)\n",
    "\n",
    "    finally:\n",
    "        print('Finished Training')\n",
    "\n",
    "        dirpath = 'saved_models'\n",
    "        PATH = '%s/%s.pth' % (dirpath, basename)\n",
    "        try:\n",
    "            os.mkdir(dirpath)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        torch.save(net.state_dict(), PATH)\n",
    "        print(\"Saved in %s.\" % PATH)\n",
    "    return PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(num_classes)\n",
    "net.to(device)\n",
    "PATH = train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 最適な成果を取得\n",
    "# best_trial = study.best_trial\n",
    "\n",
    "# その時のパラメータと学習済み係数でモデルを復元\n",
    "# net = Net(optuna.trial.FixedTrial(best_trial.params))\n",
    "\n",
    "net = Net(num_classes)\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "# net.load_state_dict(torch.load(best_trial.user_attrs['saved_path']))\n",
    "net.to(device)\n",
    "net.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images[:num_shown_images]\n",
    "labels = labels[:num_shown_images]\n",
    "\n",
    "# print images\n",
    "util.imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(num_shown_images)))\n",
    "\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(num_shown_images)))\n",
    "accuracy_per_class, accuracy = util.accuracy_of_classes(num_classes, testloader, net, device=device)\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % accuracy)\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], accuracy_per_class[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
